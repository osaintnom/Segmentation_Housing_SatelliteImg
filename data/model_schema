digraph {
	graph [size="107.85,107.85"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2179374674032 [label="
 (1, 2, 128, 128)" fillcolor=darkolivegreen1]
	2179369457680 [label=UpsampleBilinear2DBackward0]
	2179369454224 -> 2179369457680
	2179369454224 [label=ConvolutionBackward0]
	2179369452352 -> 2179369454224
	2179369452352 [label=AddBackward0]
	2179440490096 -> 2179369452352
	2179440490096 [label=AddBackward0]
	2179372662064 -> 2179440490096
	2179372662064 [label=AddBackward0]
	2179378249840 -> 2179372662064
	2179378249840 [label=AddBackward0]
	2179379407808 -> 2179378249840
	2179379407808 [label=AddBackward0]
	2179383414688 -> 2179379407808
	2179383414688 [label=ReluBackward0]
	2179440838832 -> 2179383414688
	2179440838832 [label=NativeGroupNormBackward0]
	2179440848576 -> 2179440838832
	2179440848576 [label=ConvolutionBackward0]
	2179440846656 -> 2179440848576
	2179440846656 [label=ConvolutionBackward0]
	2179440848864 -> 2179440846656
	2179440848864 [label=MaxPool2DWithIndicesBackward0]
	2179440839888 -> 2179440848864
	2179440839888 [label=ReluBackward0]
	2179440845360 -> 2179440839888
	2179440845360 [label=CudnnBatchNormBackward0]
	2179440842624 -> 2179440845360
	2179440842624 [label=ConvolutionBackward0]
	2179440841808 -> 2179440842624
	2179383812544 [label="0.m.0.0.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	2179383812544 -> 2179440841808
	2179440841808 [label=AccumulateGrad]
	2179440845264 -> 2179440845360
	2179370894752 [label="0.m.0.1.weight
 (64)" fillcolor=lightblue]
	2179370894752 -> 2179440845264
	2179440845264 [label=AccumulateGrad]
	2179440841184 -> 2179440845360
	2179375795008 [label="0.m.0.1.bias
 (64)" fillcolor=lightblue]
	2179375795008 -> 2179440841184
	2179440841184 [label=AccumulateGrad]
	2179440840752 -> 2179440846656
	2179376512960 [label="1.0.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2179376512960 -> 2179440840752
	2179440840752 [label=AccumulateGrad]
	2179440839216 -> 2179440846656
	2179376512640 [label="1.0.0.bias
 (128)" fillcolor=lightblue]
	2179376512640 -> 2179440839216
	2179440839216 [label=AccumulateGrad]
	2179440837104 -> 2179440848576
	2179376511600 [label="1.1.0.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2179376511600 -> 2179440837104
	2179440837104 [label=AccumulateGrad]
	2179440848000 -> 2179440848576
	2179376511440 [label="1.1.0.0.bias
 (64)" fillcolor=lightblue]
	2179376511440 -> 2179440848000
	2179440848000 [label=AccumulateGrad]
	2179440841856 -> 2179440838832
	2179376511280 [label="1.1.0.1.weight
 (64)" fillcolor=lightblue]
	2179376511280 -> 2179440841856
	2179440841856 [label=AccumulateGrad]
	2179440842576 -> 2179440838832
	2179376511360 [label="1.1.0.1.bias
 (64)" fillcolor=lightblue]
	2179376511360 -> 2179440842576
	2179440842576 [label=AccumulateGrad]
	2179379410448 -> 2179378249840
	2179379410448 [label=UpsampleBilinear2DBackward0]
	2179440842864 -> 2179379410448
	2179440842864 [label=ReluBackward0]
	2179440847040 -> 2179440842864
	2179440847040 [label=NativeGroupNormBackward0]
	2179440843632 -> 2179440847040
	2179440843632 [label=ConvolutionBackward0]
	2179440846512 -> 2179440843632
	2179440846512 [label=ConvolutionBackward0]
	2179440846752 -> 2179440846512
	2179440846752 [label=ReluBackward0]
	2179440846848 -> 2179440846752
	2179440846848 [label=AddBackward0]
	2179440844448 -> 2179440846848
	2179440844448 [label=CudnnBatchNormBackward0]
	2179440842048 -> 2179440844448
	2179440842048 [label=ConvolutionBackward0]
	2179440846368 -> 2179440842048
	2179440846368 [label=ReluBackward0]
	2179440843920 -> 2179440846368
	2179440843920 [label=CudnnBatchNormBackward0]
	2179440837584 -> 2179440843920
	2179440837584 [label=ConvolutionBackward0]
	2179440838160 -> 2179440837584
	2179440838160 [label=ReluBackward0]
	2179440842960 -> 2179440838160
	2179440842960 [label=AddBackward0]
	2179440843152 -> 2179440842960
	2179440843152 [label=CudnnBatchNormBackward0]
	2179440836672 -> 2179440843152
	2179440836672 [label=ConvolutionBackward0]
	2179440849200 -> 2179440836672
	2179440849200 [label=ReluBackward0]
	2179440847472 -> 2179440849200
	2179440847472 [label=CudnnBatchNormBackward0]
	2179440849008 -> 2179440847472
	2179440849008 [label=ConvolutionBackward0]
	2179440848864 -> 2179440849008
	2179440836768 -> 2179440849008
	2179377061216 [label="0.m.1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2179377061216 -> 2179440836768
	2179440836768 [label=AccumulateGrad]
	2179440848480 -> 2179440847472
	2179377062096 [label="0.m.1.0.bn1.weight
 (64)" fillcolor=lightblue]
	2179377062096 -> 2179440848480
	2179440848480 [label=AccumulateGrad]
	2179440844544 -> 2179440847472
	2179377057856 [label="0.m.1.0.bn1.bias
 (64)" fillcolor=lightblue]
	2179377057856 -> 2179440844544
	2179440844544 [label=AccumulateGrad]
	2179440836912 -> 2179440836672
	2179377062496 [label="0.m.1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2179377062496 -> 2179440836912
	2179440836912 [label=AccumulateGrad]
	2179440837056 -> 2179440843152
	2179377060016 [label="0.m.1.0.bn2.weight
 (64)" fillcolor=lightblue]
	2179377060016 -> 2179440837056
	2179440837056 [label=AccumulateGrad]
	2179440844880 -> 2179440843152
	2179377062256 [label="0.m.1.0.bn2.bias
 (64)" fillcolor=lightblue]
	2179377062256 -> 2179440844880
	2179440844880 [label=AccumulateGrad]
	2179440848864 -> 2179440842960
	2179440844592 -> 2179440837584
	2179377067136 [label="0.m.1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2179377067136 -> 2179440844592
	2179440844592 [label=AccumulateGrad]
	2179440838064 -> 2179440843920
	2179377059536 [label="0.m.1.1.bn1.weight
 (64)" fillcolor=lightblue]
	2179377059536 -> 2179440838064
	2179440838064 [label=AccumulateGrad]
	2179440842384 -> 2179440843920
	2179377067296 [label="0.m.1.1.bn1.bias
 (64)" fillcolor=lightblue]
	2179377067296 -> 2179440842384
	2179440842384 [label=AccumulateGrad]
	2179440848336 -> 2179440842048
	2179377069616 [label="0.m.1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2179377069616 -> 2179440848336
	2179440848336 [label=AccumulateGrad]
	2179440840560 -> 2179440844448
	2179377069936 [label="0.m.1.1.bn2.weight
 (64)" fillcolor=lightblue]
	2179377069936 -> 2179440840560
	2179440840560 [label=AccumulateGrad]
	2179440845120 -> 2179440844448
	2179377068176 [label="0.m.1.1.bn2.bias
 (64)" fillcolor=lightblue]
	2179377068176 -> 2179440845120
	2179440845120 [label=AccumulateGrad]
	2179440838160 -> 2179440846848
	2179440848528 -> 2179440846512
	2179376512720 [label="1.0.1.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2179376512720 -> 2179440848528
	2179440848528 [label=AccumulateGrad]
	2179440847376 -> 2179440846512
	2179376512560 [label="1.0.1.bias
 (128)" fillcolor=lightblue]
	2179376512560 -> 2179440847376
	2179440847376 [label=AccumulateGrad]
	2179440844496 -> 2179440843632
	2179376511120 [label="1.1.1.0.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2179376511120 -> 2179440844496
	2179440844496 [label=AccumulateGrad]
	2179440851792 -> 2179440843632
	2179376511040 [label="1.1.1.0.0.bias
 (64)" fillcolor=lightblue]
	2179376511040 -> 2179440851792
	2179440851792 [label=AccumulateGrad]
	2179440841232 -> 2179440847040
	2179376510880 [label="1.1.1.0.1.weight
 (64)" fillcolor=lightblue]
	2179376510880 -> 2179440841232
	2179440841232 [label=AccumulateGrad]
	2179440848384 -> 2179440847040
	2179376510800 [label="1.1.1.0.1.bias
 (64)" fillcolor=lightblue]
	2179376510800 -> 2179440848384
	2179440848384 [label=AccumulateGrad]
	2179378260784 -> 2179372662064
	2179378260784 [label=UpsampleBilinear2DBackward0]
	2179383418192 -> 2179378260784
	2179383418192 [label=ReluBackward0]
	2179440845984 -> 2179383418192
	2179440845984 [label=NativeGroupNormBackward0]
	2179440842288 -> 2179440845984
	2179440842288 [label=ConvolutionBackward0]
	2179440843824 -> 2179440842288
	2179440843824 [label=UpsampleBilinear2DBackward0]
	2179440844064 -> 2179440843824
	2179440844064 [label=ReluBackward0]
	2179440847616 -> 2179440844064
	2179440847616 [label=NativeGroupNormBackward0]
	2179440841616 -> 2179440847616
	2179440841616 [label=ConvolutionBackward0]
	2179440837536 -> 2179440841616
	2179440837536 [label=ConvolutionBackward0]
	2179440840656 -> 2179440837536
	2179440840656 [label=ReluBackward0]
	2179440846416 -> 2179440840656
	2179440846416 [label=AddBackward0]
	2179440839456 -> 2179440846416
	2179440839456 [label=CudnnBatchNormBackward0]
	2179375080800 -> 2179440839456
	2179375080800 [label=ConvolutionBackward0]
	2179383114288 -> 2179375080800
	2179383114288 [label=ReluBackward0]
	2179383114816 -> 2179383114288
	2179383114816 [label=CudnnBatchNormBackward0]
	2179383114912 -> 2179383114816
	2179383114912 [label=ConvolutionBackward0]
	2179440847232 -> 2179383114912
	2179440847232 [label=ReluBackward0]
	2179383109536 -> 2179440847232
	2179383109536 [label=AddBackward0]
	2179383111216 -> 2179383109536
	2179383111216 [label=CudnnBatchNormBackward0]
	2179383107904 -> 2179383111216
	2179383107904 [label=ConvolutionBackward0]
	2179379736352 -> 2179383107904
	2179379736352 [label=ReluBackward0]
	2179379442736 -> 2179379736352
	2179379442736 [label=CudnnBatchNormBackward0]
	2179379439952 -> 2179379442736
	2179379439952 [label=ConvolutionBackward0]
	2179440846752 -> 2179379439952
	2179373048176 -> 2179379439952
	2179376497200 [label="0.m.2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2179376497200 -> 2179373048176
	2179373048176 [label=AccumulateGrad]
	2179373040112 -> 2179379442736
	2179376497120 [label="0.m.2.0.bn1.weight
 (128)" fillcolor=lightblue]
	2179376497120 -> 2179373040112
	2179373040112 [label=AccumulateGrad]
	2179373041792 -> 2179379442736
	2179376497280 [label="0.m.2.0.bn1.bias
 (128)" fillcolor=lightblue]
	2179376497280 -> 2179373041792
	2179373041792 [label=AccumulateGrad]
	2179379436976 -> 2179383107904
	2179376497840 [label="0.m.2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2179376497840 -> 2179379436976
	2179379436976 [label=AccumulateGrad]
	2179379731408 -> 2179383111216
	2179376497760 [label="0.m.2.0.bn2.weight
 (128)" fillcolor=lightblue]
	2179376497760 -> 2179379731408
	2179379731408 [label=AccumulateGrad]
	2179379736496 -> 2179383111216
	2179376497920 [label="0.m.2.0.bn2.bias
 (128)" fillcolor=lightblue]
	2179376497920 -> 2179379736496
	2179379736496 [label=AccumulateGrad]
	2179383110736 -> 2179383109536
	2179383110736 [label=CudnnBatchNormBackward0]
	2179379432848 -> 2179383110736
	2179379432848 [label=ConvolutionBackward0]
	2179440846752 -> 2179379432848
	2179373053840 -> 2179379432848
	2179377069456 [label="0.m.2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	2179377069456 -> 2179373053840
	2179373053840 [label=AccumulateGrad]
	2179379436784 -> 2179383110736
	2179377069536 [label="0.m.2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	2179377069536 -> 2179379436784
	2179379436784 [label=AccumulateGrad]
	2179379725456 -> 2179383110736
	2179377069776 [label="0.m.2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	2179377069776 -> 2179379725456
	2179379725456 [label=AccumulateGrad]
	2179383115488 -> 2179383114912
	2179376498400 [label="0.m.2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2179376498400 -> 2179383115488
	2179383115488 [label=AccumulateGrad]
	2179383114000 -> 2179383114816
	2179376498320 [label="0.m.2.1.bn1.weight
 (128)" fillcolor=lightblue]
	2179376498320 -> 2179383114000
	2179383114000 [label=AccumulateGrad]
	2179383114336 -> 2179383114816
	2179376498480 [label="0.m.2.1.bn1.bias
 (128)" fillcolor=lightblue]
	2179376498480 -> 2179383114336
	2179383114336 [label=AccumulateGrad]
	2179383114576 -> 2179375080800
	2179376498960 [label="0.m.2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2179376498960 -> 2179383114576
	2179383114576 [label=AccumulateGrad]
	2179440849104 -> 2179440839456
	2179376498880 [label="0.m.2.1.bn2.weight
 (128)" fillcolor=lightblue]
	2179376498880 -> 2179440849104
	2179440849104 [label=AccumulateGrad]
	2179383114624 -> 2179440839456
	2179376499040 [label="0.m.2.1.bn2.bias
 (128)" fillcolor=lightblue]
	2179376499040 -> 2179383114624
	2179383114624 [label=AccumulateGrad]
	2179440847232 -> 2179440846416
	2179440836816 -> 2179440837536
	2179376512400 [label="1.0.2.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2179376512400 -> 2179440836816
	2179440836816 [label=AccumulateGrad]
	2179440843248 -> 2179440837536
	2179376512320 [label="1.0.2.bias
 (128)" fillcolor=lightblue]
	2179376512320 -> 2179440843248
	2179440843248 [label=AccumulateGrad]
	2179440845312 -> 2179440841616
	2179376510320 [label="1.1.2.0.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2179376510320 -> 2179440845312
	2179440845312 [label=AccumulateGrad]
	2179440843392 -> 2179440841616
	2179376510400 [label="1.1.2.0.0.bias
 (128)" fillcolor=lightblue]
	2179376510400 -> 2179440843392
	2179440843392 [label=AccumulateGrad]
	2179440838976 -> 2179440847616
	2179376510240 [label="1.1.2.0.1.weight
 (128)" fillcolor=lightblue]
	2179376510240 -> 2179440838976
	2179440838976 [label=AccumulateGrad]
	2179440839264 -> 2179440847616
	2179376510080 [label="1.1.2.0.1.bias
 (128)" fillcolor=lightblue]
	2179376510080 -> 2179440839264
	2179440839264 [label=AccumulateGrad]
	2179440846896 -> 2179440842288
	2179376509920 [label="1.1.2.1.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2179376509920 -> 2179440846896
	2179440846896 [label=AccumulateGrad]
	2179440842144 -> 2179440842288
	2179376509840 [label="1.1.2.1.0.bias
 (64)" fillcolor=lightblue]
	2179376509840 -> 2179440842144
	2179440842144 [label=AccumulateGrad]
	2179440842432 -> 2179440845984
	2179376509680 [label="1.1.2.1.1.weight
 (64)" fillcolor=lightblue]
	2179376509680 -> 2179440842432
	2179440842432 [label=AccumulateGrad]
	2179440849152 -> 2179440845984
	2179376509600 [label="1.1.2.1.1.bias
 (64)" fillcolor=lightblue]
	2179376509600 -> 2179440849152
	2179440849152 [label=AccumulateGrad]
	2179372662400 -> 2179440490096
	2179372662400 [label=UpsampleBilinear2DBackward0]
	2179378256272 -> 2179372662400
	2179378256272 [label=ReluBackward0]
	2179440836960 -> 2179378256272
	2179440836960 [label=NativeGroupNormBackward0]
	2179440848144 -> 2179440836960
	2179440848144 [label=ConvolutionBackward0]
	2179440848048 -> 2179440848144
	2179440848048 [label=UpsampleBilinear2DBackward0]
	2179383115680 -> 2179440848048
	2179383115680 [label=ReluBackward0]
	2179383115152 -> 2179383115680
	2179383115152 [label=NativeGroupNormBackward0]
	2179383115728 -> 2179383115152
	2179383115728 [label=ConvolutionBackward0]
	2179373046496 -> 2179383115728
	2179373046496 [label=UpsampleBilinear2DBackward0]
	2179372471376 -> 2179373046496
	2179372471376 [label=ReluBackward0]
	2179372471472 -> 2179372471376
	2179372471472 [label=NativeGroupNormBackward0]
	2179372473920 -> 2179372471472
	2179372473920 [label=ConvolutionBackward0]
	2179378535184 -> 2179372473920
	2179378535184 [label=ConvolutionBackward0]
	2179369211632 -> 2179378535184
	2179369211632 [label=ReluBackward0]
	2179374125488 -> 2179369211632
	2179374125488 [label=AddBackward0]
	2179374121696 -> 2179374125488
	2179374121696 [label=CudnnBatchNormBackward0]
	2179374124240 -> 2179374121696
	2179374124240 [label=ConvolutionBackward0]
	2179374136336 -> 2179374124240
	2179374136336 [label=ReluBackward0]
	2179374122080 -> 2179374136336
	2179374122080 [label=CudnnBatchNormBackward0]
	2179374125392 -> 2179374122080
	2179374125392 [label=ConvolutionBackward0]
	2179374126976 -> 2179374125392
	2179374126976 [label=ReluBackward0]
	2179374123616 -> 2179374126976
	2179374123616 [label=AddBackward0]
	2179374121456 -> 2179374123616
	2179374121456 [label=CudnnBatchNormBackward0]
	2179374121024 -> 2179374121456
	2179374121024 [label=ConvolutionBackward0]
	2179374137296 -> 2179374121024
	2179374137296 [label=ReluBackward0]
	2179374136192 -> 2179374137296
	2179374136192 [label=CudnnBatchNormBackward0]
	2179374134704 -> 2179374136192
	2179374134704 [label=ConvolutionBackward0]
	2179440840656 -> 2179374134704
	2179374122752 -> 2179374134704
	2179376500320 [label="0.m.3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2179376500320 -> 2179374122752
	2179374122752 [label=AccumulateGrad]
	2179374134992 -> 2179374136192
	2179376500240 [label="0.m.3.0.bn1.weight
 (256)" fillcolor=lightblue]
	2179376500240 -> 2179374134992
	2179374134992 [label=AccumulateGrad]
	2179374122176 -> 2179374136192
	2179376500400 [label="0.m.3.0.bn1.bias
 (256)" fillcolor=lightblue]
	2179376500400 -> 2179374122176
	2179374122176 [label=AccumulateGrad]
	2179374124192 -> 2179374121024
	2179376500960 [label="0.m.3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2179376500960 -> 2179374124192
	2179374124192 [label=AccumulateGrad]
	2179374125104 -> 2179374121456
	2179376500880 [label="0.m.3.0.bn2.weight
 (256)" fillcolor=lightblue]
	2179376500880 -> 2179374125104
	2179374125104 [label=AccumulateGrad]
	2179374121360 -> 2179374121456
	2179376501040 [label="0.m.3.0.bn2.bias
 (256)" fillcolor=lightblue]
	2179376501040 -> 2179374121360
	2179374121360 [label=AccumulateGrad]
	2179374135472 -> 2179374123616
	2179374135472 [label=CudnnBatchNormBackward0]
	2179374130432 -> 2179374135472
	2179374130432 [label=ConvolutionBackward0]
	2179440840656 -> 2179374130432
	2179374136240 -> 2179374130432
	2179376499520 [label="0.m.3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	2179376499520 -> 2179374136240
	2179374136240 [label=AccumulateGrad]
	2179374135856 -> 2179374135472
	2179376499600 [label="0.m.3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	2179376499600 -> 2179374135856
	2179374135856 [label=AccumulateGrad]
	2179374136144 -> 2179374135472
	2179376499680 [label="0.m.3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	2179376499680 -> 2179374136144
	2179374136144 [label=AccumulateGrad]
	2179374126160 -> 2179374125392
	2179376501520 [label="0.m.3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2179376501520 -> 2179374126160
	2179374126160 [label=AccumulateGrad]
	2179374122272 -> 2179374122080
	2179376501440 [label="0.m.3.1.bn1.weight
 (256)" fillcolor=lightblue]
	2179376501440 -> 2179374122272
	2179374122272 [label=AccumulateGrad]
	2179374121312 -> 2179374122080
	2179376501600 [label="0.m.3.1.bn1.bias
 (256)" fillcolor=lightblue]
	2179376501600 -> 2179374121312
	2179374121312 [label=AccumulateGrad]
	2179374127552 -> 2179374124240
	2179376502160 [label="0.m.3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2179376502160 -> 2179374127552
	2179374127552 [label=AccumulateGrad]
	2179374124096 -> 2179374121696
	2179376502080 [label="0.m.3.1.bn2.weight
 (256)" fillcolor=lightblue]
	2179376502080 -> 2179374124096
	2179374124096 [label=AccumulateGrad]
	2179374125008 -> 2179374121696
	2179376502240 [label="0.m.3.1.bn2.bias
 (256)" fillcolor=lightblue]
	2179376502240 -> 2179374125008
	2179374125008 [label=AccumulateGrad]
	2179374126976 -> 2179374125488
	2179379507792 -> 2179378535184
	2179376512240 [label="1.0.3.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2179376512240 -> 2179379507792
	2179379507792 [label=AccumulateGrad]
	2179379503328 -> 2179378535184
	2179376512080 [label="1.0.3.bias
 (128)" fillcolor=lightblue]
	2179376512080 -> 2179379503328
	2179379503328 [label=AccumulateGrad]
	2179380892272 -> 2179372473920
	2179376509120 [label="1.1.3.0.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2179376509120 -> 2179380892272
	2179380892272 [label=AccumulateGrad]
	2179369219792 -> 2179372473920
	2179376509200 [label="1.1.3.0.0.bias
 (128)" fillcolor=lightblue]
	2179376509200 -> 2179369219792
	2179369219792 [label=AccumulateGrad]
	2179380897936 -> 2179372471472
	2179376509040 [label="1.1.3.0.1.weight
 (128)" fillcolor=lightblue]
	2179376509040 -> 2179380897936
	2179380897936 [label=AccumulateGrad]
	2179380903216 -> 2179372471472
	2179376508880 [label="1.1.3.0.1.bias
 (128)" fillcolor=lightblue]
	2179376508880 -> 2179380903216
	2179380903216 [label=AccumulateGrad]
	2179373053408 -> 2179383115728
	2179376508720 [label="1.1.3.1.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2179376508720 -> 2179373053408
	2179373053408 [label=AccumulateGrad]
	2179373043040 -> 2179383115728
	2179376508640 [label="1.1.3.1.0.bias
 (128)" fillcolor=lightblue]
	2179376508640 -> 2179373043040
	2179373043040 [label=AccumulateGrad]
	2179383114672 -> 2179383115152
	2179376508480 [label="1.1.3.1.1.weight
 (128)" fillcolor=lightblue]
	2179376508480 -> 2179383114672
	2179383114672 [label=AccumulateGrad]
	2179383114768 -> 2179383115152
	2179376508400 [label="1.1.3.1.1.bias
 (128)" fillcolor=lightblue]
	2179376508400 -> 2179383114768
	2179383114768 [label=AccumulateGrad]
	2179440840464 -> 2179440848144
	2179376507920 [label="1.1.3.2.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2179376507920 -> 2179440840464
	2179440840464 [label=AccumulateGrad]
	2179440838592 -> 2179440848144
	2179376508000 [label="1.1.3.2.0.bias
 (64)" fillcolor=lightblue]
	2179376508000 -> 2179440838592
	2179440838592 [label=AccumulateGrad]
	2179440836864 -> 2179440836960
	2179376507840 [label="1.1.3.2.1.weight
 (64)" fillcolor=lightblue]
	2179376507840 -> 2179440836864
	2179440836864 [label=AccumulateGrad]
	2179440843776 -> 2179440836960
	2179376507680 [label="1.1.3.2.1.bias
 (64)" fillcolor=lightblue]
	2179376507680 -> 2179440843776
	2179440843776 [label=AccumulateGrad]
	2179440482944 -> 2179369452352
	2179440482944 [label=UpsampleBilinear2DBackward0]
	2179378263280 -> 2179440482944
	2179378263280 [label=ReluBackward0]
	2179440841568 -> 2179378263280
	2179440841568 [label=NativeGroupNormBackward0]
	2179383114864 -> 2179440841568
	2179383114864 [label=ConvolutionBackward0]
	2179380895440 -> 2179383114864
	2179380895440 [label=UpsampleBilinear2DBackward0]
	2179379509856 -> 2179380895440
	2179379509856 [label=ReluBackward0]
	2179374121792 -> 2179379509856
	2179374121792 [label=NativeGroupNormBackward0]
	2179374127216 -> 2179374121792
	2179374127216 [label=ConvolutionBackward0]
	2179374122416 -> 2179374127216
	2179374122416 [label=UpsampleBilinear2DBackward0]
	2179374136528 -> 2179374122416
	2179374136528 [label=ReluBackward0]
	2179374136048 -> 2179374136528
	2179374136048 [label=NativeGroupNormBackward0]
	2179374135952 -> 2179374136048
	2179374135952 [label=ConvolutionBackward0]
	2179374133360 -> 2179374135952
	2179374133360 [label=UpsampleBilinear2DBackward0]
	2179374122560 -> 2179374133360
	2179374122560 [label=ReluBackward0]
	2179374123040 -> 2179374122560
	2179374123040 [label=NativeGroupNormBackward0]
	2179374123952 -> 2179374123040
	2179374123952 [label=ConvolutionBackward0]
	2179374122032 -> 2179374123952
	2179374122032 [label=ConvolutionBackward0]
	2179057810400 -> 2179374122032
	2179057810400 [label=ReluBackward0]
	2179442451520 -> 2179057810400
	2179442451520 [label=AddBackward0]
	2179442453824 -> 2179442451520
	2179442453824 [label=CudnnBatchNormBackward0]
	2179369355536 -> 2179442453824
	2179369355536 [label=ConvolutionBackward0]
	2179369361104 -> 2179369355536
	2179369361104 [label=ReluBackward0]
	2179369365424 -> 2179369361104
	2179369365424 [label=CudnnBatchNormBackward0]
	2179369364848 -> 2179369365424
	2179369364848 [label=ConvolutionBackward0]
	2179442453776 -> 2179369364848
	2179442453776 [label=ReluBackward0]
	2179369359472 -> 2179442453776
	2179369359472 [label=AddBackward0]
	2179369368400 -> 2179369359472
	2179369368400 [label=CudnnBatchNormBackward0]
	2179369368064 -> 2179369368400
	2179369368064 [label=ConvolutionBackward0]
	2179369358656 -> 2179369368064
	2179369358656 [label=ReluBackward0]
	2179369363168 -> 2179369358656
	2179369363168 [label=CudnnBatchNormBackward0]
	2179369362208 -> 2179369363168
	2179369362208 [label=ConvolutionBackward0]
	2179369211632 -> 2179369362208
	2179369361440 -> 2179369362208
	2179376503520 [label="0.m.4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2179376503520 -> 2179369361440
	2179369361440 [label=AccumulateGrad]
	2179369364752 -> 2179369363168
	2179376503440 [label="0.m.4.0.bn1.weight
 (512)" fillcolor=lightblue]
	2179376503440 -> 2179369364752
	2179369364752 [label=AccumulateGrad]
	2179369363456 -> 2179369363168
	2179376503600 [label="0.m.4.0.bn1.bias
 (512)" fillcolor=lightblue]
	2179376503600 -> 2179369363456
	2179369363456 [label=AccumulateGrad]
	2179369356112 -> 2179369368064
	2179376504160 [label="0.m.4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2179376504160 -> 2179369356112
	2179369356112 [label=AccumulateGrad]
	2179369363648 -> 2179369368400
	2179376504000 [label="0.m.4.0.bn2.weight
 (512)" fillcolor=lightblue]
	2179376504000 -> 2179369363648
	2179369363648 [label=AccumulateGrad]
	2179369364176 -> 2179369368400
	2179376504240 [label="0.m.4.0.bn2.bias
 (512)" fillcolor=lightblue]
	2179376504240 -> 2179369364176
	2179369364176 [label=AccumulateGrad]
	2179369355680 -> 2179369359472
	2179369355680 [label=CudnnBatchNormBackward0]
	2179369359952 -> 2179369355680
	2179369359952 [label=ConvolutionBackward0]
	2179369211632 -> 2179369359952
	2179369360240 -> 2179369359952
	2179376502720 [label="0.m.4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	2179376502720 -> 2179369360240
	2179369360240 [label=AccumulateGrad]
	2179369361920 -> 2179369355680
	2179376502800 [label="0.m.4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	2179376502800 -> 2179369361920
	2179369361920 [label=AccumulateGrad]
	2179369355296 -> 2179369355680
	2179376502880 [label="0.m.4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	2179376502880 -> 2179369355296
	2179369355296 [label=AccumulateGrad]
	2179369366336 -> 2179369364848
	2179376504720 [label="0.m.4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2179376504720 -> 2179369366336
	2179369366336 [label=AccumulateGrad]
	2179369369312 -> 2179369365424
	2179376504640 [label="0.m.4.1.bn1.weight
 (512)" fillcolor=lightblue]
	2179376504640 -> 2179369369312
	2179369369312 [label=AccumulateGrad]
	2179369354384 -> 2179369365424
	2179376504800 [label="0.m.4.1.bn1.bias
 (512)" fillcolor=lightblue]
	2179376504800 -> 2179369354384
	2179369354384 [label=AccumulateGrad]
	2179369369552 -> 2179369355536
	2179376505360 [label="0.m.4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2179376505360 -> 2179369369552
	2179369369552 [label=AccumulateGrad]
	2179369359424 -> 2179442453824
	2179376505280 [label="0.m.4.1.bn2.weight
 (512)" fillcolor=lightblue]
	2179376505280 -> 2179369359424
	2179369359424 [label=AccumulateGrad]
	2179369359616 -> 2179442453824
	2179376505440 [label="0.m.4.1.bn2.bias
 (512)" fillcolor=lightblue]
	2179376505440 -> 2179369359616
	2179369359616 [label=AccumulateGrad]
	2179442453776 -> 2179442451520
	2179442454496 -> 2179374122032
	2179376511840 [label="1.0.4.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2179376511840 -> 2179442454496
	2179442454496 [label=AccumulateGrad]
	2179442447632 -> 2179374122032
	2179376511760 [label="1.0.4.bias
 (128)" fillcolor=lightblue]
	2179376511760 -> 2179442447632
	2179442447632 [label=AccumulateGrad]
	2179374123136 -> 2179374123952
	2179376507520 [label="1.1.4.0.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2179376507520 -> 2179374123136
	2179374123136 [label=AccumulateGrad]
	2179374122608 -> 2179374123952
	2179376507440 [label="1.1.4.0.0.bias
 (128)" fillcolor=lightblue]
	2179376507440 -> 2179374122608
	2179374122608 [label=AccumulateGrad]
	2179374135664 -> 2179374123040
	2179376507280 [label="1.1.4.0.1.weight
 (128)" fillcolor=lightblue]
	2179376507280 -> 2179374135664
	2179374135664 [label=AccumulateGrad]
	2179374133792 -> 2179374123040
	2179376507200 [label="1.1.4.0.1.bias
 (128)" fillcolor=lightblue]
	2179376507200 -> 2179374133792
	2179374133792 [label=AccumulateGrad]
	2179374127072 -> 2179374135952
	2179376506720 [label="1.1.4.1.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2179376506720 -> 2179374127072
	2179374127072 [label=AccumulateGrad]
	2179374125440 -> 2179374135952
	2179376506800 [label="1.1.4.1.0.bias
 (128)" fillcolor=lightblue]
	2179376506800 -> 2179374125440
	2179374125440 [label=AccumulateGrad]
	2179374135424 -> 2179374136048
	2179376506560 [label="1.1.4.1.1.weight
 (128)" fillcolor=lightblue]
	2179376506560 -> 2179374135424
	2179374135424 [label=AccumulateGrad]
	2179374136096 -> 2179374136048
	2179376506640 [label="1.1.4.1.1.bias
 (128)" fillcolor=lightblue]
	2179376506640 -> 2179374136096
	2179374136096 [label=AccumulateGrad]
	2179374123856 -> 2179374127216
	2179376505920 [label="1.1.4.2.0.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2179376505920 -> 2179374123856
	2179374123856 [label=AccumulateGrad]
	2179374123520 -> 2179374127216
	2179376506320 [label="1.1.4.2.0.bias
 (128)" fillcolor=lightblue]
	2179376506320 -> 2179374123520
	2179374123520 [label=AccumulateGrad]
	2179374134656 -> 2179374121792
	2179376506880 [label="1.1.4.2.1.weight
 (128)" fillcolor=lightblue]
	2179376506880 -> 2179374134656
	2179374134656 [label=AccumulateGrad]
	2179374124864 -> 2179374121792
	2179376507120 [label="1.1.4.2.1.bias
 (128)" fillcolor=lightblue]
	2179376507120 -> 2179374124864
	2179374124864 [label=AccumulateGrad]
	2179373050432 -> 2179383114864
	2179376508320 [label="1.1.4.3.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2179376508320 -> 2179373050432
	2179373050432 [label=AccumulateGrad]
	2179372476656 -> 2179383114864
	2179376508560 [label="1.1.4.3.0.bias
 (64)" fillcolor=lightblue]
	2179376508560 -> 2179372476656
	2179372476656 [label=AccumulateGrad]
	2179383114048 -> 2179440841568
	2179376509280 [label="1.1.4.3.1.weight
 (64)" fillcolor=lightblue]
	2179376509280 -> 2179383114048
	2179383114048 [label=AccumulateGrad]
	2179440839120 -> 2179440841568
	2179376509520 [label="1.1.4.3.1.bias
 (64)" fillcolor=lightblue]
	2179376509520 -> 2179440839120
	2179440839120 [label=AccumulateGrad]
	2179369465264 -> 2179369454224
	2179376510720 [label="1.3.weight
 (2, 64, 1, 1)" fillcolor=lightblue]
	2179376510720 -> 2179369465264
	2179369465264 [label=AccumulateGrad]
	2179369454752 -> 2179369454224
	2179376510960 [label="1.3.bias
 (2)" fillcolor=lightblue]
	2179376510960 -> 2179369454752
	2179369454752 [label=AccumulateGrad]
	2179369457680 -> 2179374674032
}
