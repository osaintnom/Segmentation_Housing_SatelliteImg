{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 0 : importe de librerias y configuraciond el entrono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import glob\n",
    "import utils\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import subprocess\n",
    "import rastervision\n",
    "import rasterio\n",
    "from subprocess import check_output\n",
    "from aux_functions import download_blob_from_azure\n",
    "\n",
    "from rastervision.core.data import RasterioSource, MinMaxTransformer\n",
    "\n",
    "from rastervision.core.data import (\n",
    "    ClassConfig, GeoJSONVectorSource, RasterioCRSTransformer,\n",
    "    RasterizedSource, ClassInferenceTransformer)\n",
    "\n",
    "from rastervision.core.data import SemanticSegmentationLabelSource\n",
    "\n",
    "from rastervision.core.data.utils.geojson import get_polygons_from_uris\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from rastervision.pytorch_learner import (\n",
    "    SemanticSegmentationRandomWindowGeoDataset, SemanticSegmentationSlidingWindowGeoDataset, SemanticSegmentationVisualizer)\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "from rastervision.pytorch_learner import SemanticSegmentationGeoDataConfig\n",
    "from rastervision.pytorch_learner import SolverConfig\n",
    "from rastervision.pytorch_learner import SemanticSegmentationLearnerConfig\n",
    "from rastervision.pytorch_learner import SemanticSegmentationLearner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDAL_DATA has been set to: C:\\Users\\oltie\\anaconda3\\envs\\ssmodel_env\\Lib\\site-packages\\rasterio\\gdal_data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# os.environ['GDAL_DATA'] = check_output('pip show rasterio | grep Location | awk \\'{print $NF\"/rasterio/gdal_data/\"}\\'', shell=True).decode().strip()\n",
    "os.environ['AWS_NO_SIGN_REQUEST'] = 'YES'\n",
    "\n",
    "\n",
    "# Get the location of rasterio\n",
    "rasterio_location = check_output('pip show rasterio', shell=True).decode()\n",
    "\n",
    "# Find the line that specifies the location\n",
    "gdal_data_path = None\n",
    "for line in rasterio_location.splitlines():\n",
    "    if line.startswith(\"Location:\"):\n",
    "        gdal_data_path = os.path.join(line.split(\":\", 1)[1].strip(), 'rasterio', 'gdal_data')\n",
    "        break\n",
    "\n",
    "# Set the GDAL_DATA environment variable if we found the path\n",
    "if gdal_data_path:\n",
    "    os.environ['GDAL_DATA'] = gdal_data_path\n",
    "    print(f\"GDAL_DATA has been set to: {gdal_data_path}\")\n",
    "else:\n",
    "    print(\"Could not find the GDAL data path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set global seed for reproducibility\n",
    "def set_global_seed(seed):\n",
    "    random.seed(seed)  # Python's random module\n",
    "    np.random.seed(seed)  # NumPy's random module\n",
    "    torch.manual_seed(seed)  # PyTorch seed for CPU\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)  # PyTorch seed for current GPU\n",
    "        torch.cuda.manual_seed_all(seed)  # PyTorch seed for all GPUs (if using multi-GPU)\n",
    "\n",
    "# Prepare cuDNN for deterministic behavior\n",
    "def prepare_cudnn(deterministic=True):\n",
    "    torch.backends.cudnn.deterministic = deterministic  # cuDNN deterministic setting\n",
    "    torch.backends.cudnn.benchmark = not deterministic  # Disable cuDNN benchmarking if deterministic\n",
    "\n",
    "# Set the seed and configure cuDNN\n",
    "SEED = 42\n",
    "set_global_seed(SEED)\n",
    "prepare_cudnn(deterministic=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Descargar la Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023.tif: 100%|##########| 362M/362M [01:07<00:00, 5.35MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded '2023.tif' to './data/train/img/2023.tif'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023.tif: 100%|##########| 362M/362M [00:43<00:00, 8.36MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded '2023.tif' to './data/val/img/2023.tif'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#imagenes\n",
    "train_img_uri = \"./data/train/img/\"\n",
    "train_img_name = \"2023.tif\"\n",
    "\n",
    "download_blob_from_azure(train_img_name,train_img_uri)\n",
    "train_iimg_uri = train_img_uri + train_img_name\n",
    "#__________________________________________________________#\n",
    "val_img_uri = \"./data/val/img/\"\n",
    "val_img_name = \"2023.tif\"\n",
    "\n",
    "download_blob_from_azure(val_img_name, val_img_uri)\n",
    "val_img_uri = val_img_uri + val_img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023_viviendas.geojson: 100%|##########| 1.58M/1.58M [00:00<00:00, 6.18MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded '2023_viviendas.geojson' to './data/train/labels/2023_viviendas.geojson'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_labels_uri = \"./data/train/labels/\"\n",
    "train_labels_name = \"2023_viviendas.geojson\"\n",
    "\n",
    "download_blob_from_azure(train_labels_name,train_labels_uri)\n",
    "train_labels_uri = train_labels_uri+train_labels_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023_viviendas.geojson: 100%|##########| 1.58M/1.58M [00:00<00:00, 6.77MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded '2023_viviendas.geojson' to './data/train/labels/2023_viviendas.geojson'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023_viviendas.geojson: 100%|##########| 1.58M/1.58M [00:00<00:00, 6.98MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded '2023_viviendas.geojson' to './data/val/labels/2023_viviendas.geojson'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#labels\n",
    "train_labels_uri = \"./data/train/labels/\"\n",
    "train_labels_name = \"2023_viviendas.geojson\"\n",
    "\n",
    "download_blob_from_azure(train_labels_name,train_labels_uri)\n",
    "train_labels_uri = train_labels_uri+train_labels_name\n",
    "#__________________________________________________________#\n",
    "val_labels_uri = \"./data/val/labels/\"\n",
    "val_labels_name = \"2023_viviendas.geojson\"\n",
    "\n",
    "download_blob_from_azure(val_labels_name, val_labels_uri)\n",
    "val_labels_uri = val_labels_uri + val_labels_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023_viviendas.geojson: 100%|##########| 1.58M/1.58M [00:00<00:00, 7.21MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded '2023_viviendas.geojson' to './data/val/labels/2023_viviendas.geojson'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_labels_uri = \"./data/val/labels/\"\n",
    "val_labels_name = \"2023_viviendas.geojson\"\n",
    "\n",
    "download_blob_from_azure(val_labels_name, val_labels_uri)\n",
    "val_labels_uri = val_labels_uri + val_labels_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_aoi.geojson: 100%|##########| 136k/136k [00:00<00:00, 747kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'train_aoi.geojson' to './data/train/train_aoi.geojson'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_aoi.geojson: 100%|##########| 83.8k/83.8k [00:00<00:00, 264kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 'val_aoi.geojson' to './data/val/val_aoi.geojson'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_blob_from_azure('train_aoi.geojson', './data/train/')\n",
    "download_blob_from_azure('val_aoi.geojson', './data/val/')\n",
    "\n",
    "train_AoI_uri = './data/train/train_aoi.geojson'\n",
    "val_AoI_uri = './data/val/val_aoi.geojson'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Preprocesamiento: extracciÃ³n de recortes para entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AquÃ­ definimos las clases (tipos de objeto) presentes en nuestras anotaciones\n",
    "# en este caso tenemos sÃ³lo una, que indicamos como \"viviendas precarias\" .\n",
    "# hay un clase adicional, implÃ­cita, que es \"background\" -el fondo, todo lo que\n",
    "# no corresponde a objetos de intÃ©res\n",
    "\n",
    "class_config = ClassConfig(\n",
    "    names=['background', 'viviendas precarias'],\n",
    "    colors=['lightgray', 'darkred'],\n",
    "    null_class='background')\n",
    "\n",
    "\n",
    "# el tamaÃ±o en pÃ­xeles de los recortes cuadrados\n",
    "window_size = 128\n",
    "\n",
    "# AquÃ­ definimos algunas transformaciones a realizar a los recorte del dataset\n",
    "# de entrenamiento: cambiar al azar la saturaciÃ³n, el brillo, rotarlos, ocultar\n",
    "# algunos pixeles. Todo esto sirve para entrenar un algoritmo de detecciÃ³n\n",
    "# mÃ¡s robusto a diferencias que puedan tener las futuras imÃ¡genes a las que\n",
    "# se aplique\n",
    "data_augmentation_transform = A.Compose([\n",
    "    A.Flip(),\n",
    "    A.ShiftScaleRotate(),\n",
    "    A.OneOf([\n",
    "        A.HueSaturationValue(hue_shift_limit=10),\n",
    "        A.RandomBrightnessContrast(),\n",
    "        A.RandomGamma(),\n",
    "        A.RGBShift(),\n",
    "        # A.ToGray(),\n",
    "        # A.ToSepia(),\n",
    "    ]),\n",
    "    A.CoarseDropout(max_height=int(window_size/6), max_width=int(window_size/6), max_holes=4)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_val_ds(image_uris, class_config, AoI_file_dest_uri, val_labels_uri, window_size):\n",
    "    datasets = []\n",
    "    \n",
    "    # Ensure image_uris is a list, even if there is only one image\n",
    "    if not isinstance(image_uris, list):\n",
    "        image_uris = [image_uris]\n",
    "\n",
    "    for image_uri in image_uris:\n",
    "        val_ds = SemanticSegmentationSlidingWindowGeoDataset.from_uris(\n",
    "            class_config=class_config,\n",
    "            aoi_uri=AoI_file_dest_uri,\n",
    "            image_uri=image_uri,\n",
    "            label_vector_uri=val_labels_uri,\n",
    "            label_vector_default_class_id=class_config.get_class_id('viviendas precarias'),\n",
    "            image_raster_source_kw=dict(allow_streaming=True, raster_transformers=[MinMaxTransformer()]),\n",
    "            size=window_size,\n",
    "            stride=window_size,\n",
    "            transform=A.Resize(window_size, window_size)\n",
    "        )\n",
    "        datasets.append(val_ds)\n",
    "\n",
    "    # Concatenate all datasets if any exist, otherwise return None\n",
    "    combined_val_ds = sum(datasets[1:], datasets[0]) if datasets else None\n",
    "    \n",
    "    return combined_val_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear el dataset de validaciÃ³n\n",
    "val_ds = create_val_ds(\n",
    "    image_uris=val_img_uri,\n",
    "    class_config=class_config,\n",
    "    AoI_file_dest_uri=val_AoI_uri,\n",
    "    val_labels_uri=val_labels_uri,\n",
    "    window_size=window_size\n",
    ")\n",
    "\n",
    "len(val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = SemanticSegmentationVisualizer(\n",
    "    class_names=class_config.names, class_colors=class_config.colors)\n",
    "\n",
    "x, y = val_ds[10]\n",
    "\n",
    "vis.plot_batch(x.unsqueeze(0), y.unsqueeze(0), show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_ds(image_uris, class_config, AoI_file_dest_uri, train_labels_uri, window_size, sample_size, data_augmentation_transform):\n",
    "    datasets = []\n",
    "    \n",
    "    # Ensure image_uris is a list, even if there is only one image\n",
    "    if not isinstance(image_uris, list):\n",
    "        image_uris = [image_uris]\n",
    "\n",
    "    for image_uri in image_uris:\n",
    "        train_ds = SemanticSegmentationRandomWindowGeoDataset.from_uris(\n",
    "            class_config=class_config,\n",
    "            aoi_uri=AoI_file_dest_uri,\n",
    "            image_uri=image_uri,\n",
    "            label_vector_uri=train_labels_uri,\n",
    "            label_vector_default_class_id=class_config.get_class_id('viviendas precarias'),\n",
    "            image_raster_source_kw=dict(allow_streaming=True, raster_transformers=[MinMaxTransformer()]),\n",
    "            size_lims=(window_size, window_size + 1),\n",
    "            out_size=window_size,\n",
    "            padding=100,  # Adjust the padding as needed\n",
    "            max_windows=sample_size,\n",
    "            transform=data_augmentation_transform\n",
    "        )\n",
    "        datasets.append(train_ds)\n",
    "    \n",
    "    # Concatenate all datasets if any exist, otherwise return None\n",
    "    combined_train_ds = sum(datasets[1:], datasets[0]) if datasets else None\n",
    "    \n",
    "    return combined_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el dataset de entrenamiento\n",
    "train_ds = create_train_ds(\n",
    "    image_uris=train_img_uri,\n",
    "    class_config=class_config,\n",
    "    AoI_file_dest_uri=train_AoI_uri,\n",
    "    train_labels_uri=train_labels_uri,\n",
    "    window_size=window_size,\n",
    "    sample_size= len(val_ds)*10, #como las area de val es mas chica me aseguro de que train tenga 10 veces mas de imagenes para cubrir mejor el area con random windows.\n",
    "    data_augmentation_transform=data_augmentation_transform\n",
    ")\n",
    "\n",
    "len(train_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class LongTargetDataset(Dataset):\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base_dataset = base_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.base_dataset[idx]\n",
    "        y = y.long()  # Ensure target is LongTensor\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap train and validation datasets\n",
    "train_ds = LongTargetDataset(train_ds)\n",
    "val_ds = LongTargetDataset(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = vis.get_batch(train_ds, 5)\n",
    "\n",
    "vis.plot_batch(x, y, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load(\n",
    "    'AdeelH/pytorch-fpn:0.3',\n",
    "    'make_fpn_resnet',\n",
    "    name='resnet18',\n",
    "    fpn_type='panoptic',\n",
    "    num_classes=len(class_config),\n",
    "    fpn_channels=128,\n",
    "    in_channels=3,\n",
    "    out_size=(window_size, window_size),\n",
    "    pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rastervision.pytorch_learner.learner_config import ExternalModuleConfig\n",
    "\n",
    "# # Definir external_loss_def para Focal Loss\n",
    "# external_loss_def = ExternalModuleConfig(\n",
    "#     entrypoint='FocalLoss',  # Definir el nombre de la funciÃ³n de entrada\n",
    "#     github_repo='your/repo',  # ReemplazÃ¡ con el repositorio correcto que contiene Focal Loss\n",
    "#     entrypoint_kwargs={'alpha': 1.0, 'gamma': 2.0},  # ParÃ¡metros de Focal Loss\n",
    "#     force_reload=False  # Puedes ajustar esto si necesitas forzar la recarga\n",
    "# )\n",
    "\n",
    "# # ConfiguraciÃ³n del solver con Focal Loss\n",
    "# solver_cfg = SolverConfig(\n",
    "#     batch_sz=50,\n",
    "#     lr=3e-2,\n",
    "#     num_epochs=10,\n",
    "#     external_loss_def=external_loss_def,  # Usar la definiciÃ³n externa de Focal Loss\n",
    "#     class_loss_weights=None  # No es necesario especificar class_loss_weights ya que Focal Loss maneja esto\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of epochs and the directory to save the model\n",
    "n_epochs = 1000\n",
    "model_folder = f\"./data/models/bundle_{n_epochs}/\"\n",
    "\n",
    "# Define the batch size for training\n",
    "batch_images = 100\n",
    "\n",
    "# Configure the dataset with the class information\n",
    "data_cfg = SemanticSegmentationGeoDataConfig(\n",
    "    class_config=class_config,\n",
    "    num_workers=0  # Set to 0 for Google Colab, to avoid multiprocessing issues\n",
    ")\n",
    "\n",
    "# Configure the solver (optimizer and scheduler)\n",
    "solver_cfg = SolverConfig(\n",
    "    batch_sz=batch_images,\n",
    "    lr=3e-2,\n",
    "    num_epochs=n_epochs,  # Specify number of epochs in the solver config\n",
    "    class_loss_weights=[1.0, 10.0]  # Lower weight for background, higher for houses (nn.CrossEntropyLoss)\n",
    ")\n",
    "\n",
    "# Build the optimizer and scheduler from solver configuration\n",
    "optimizer = solver_cfg.build_optimizer(model)\n",
    "scheduler = solver_cfg.build_epoch_scheduler(optimizer)\n",
    "\n",
    "# Combine everything into the learner configuration\n",
    "learner_cfg = SemanticSegmentationLearnerConfig(\n",
    "    data=data_cfg,\n",
    "    solver=solver_cfg\n",
    ")\n",
    "\n",
    "# Instantiate the learner with the built optimizer and scheduler\n",
    "learner = SemanticSegmentationLearner(\n",
    "    cfg=learner_cfg,\n",
    "    output_dir=model_folder,\n",
    "    model=model,\n",
    "    train_ds=train_ds,\n",
    "    valid_ds=val_ds,\n",
    "    training=True\n",
    ")\n",
    "\n",
    "# Now manually set the optimizer and scheduler into the learner if needed\n",
    "learner.optimizer = optimizer\n",
    "learner.scheduler = scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.CyclicLR at 0x2208db04740>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir el optimizador (TODAVIA NO FUE USADO)\n",
    "optimizer = learner.build_optimizer()\n",
    "optimizer\n",
    "#or\n",
    "optimizer = solver_cfg.build_optimizer(model)\n",
    "optimizer\n",
    "\n",
    "scheduler = solver_cfg.build_epoch_scheduler(optimizer)\n",
    "scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = f\"./data/models/bundle_{n_epochs}/tb-logs\"\n",
    "%tensorboard --bind_all --logdir $logdir --reload_interval 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicia el entrenamiento\n",
    "learner.train(epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.plot_predictions(split='valid', show=True,batch_limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_model_bundle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine_tuning:\n",
    "    #BSUCAR NUEVA DATA Y HACER LOS DATASETS\n",
    "    from rastervision.pytorch_learner import SemanticSegmentationLearner\n",
    "\n",
    "    learner = SemanticSegmentationLearner.from_model_bundle(\n",
    "        model_bundle_uri=f'data/models/bundle_{n_epochs}/model-bundle.zip',\n",
    "        output_dir=f'data/models/bundle_{n_epochs}_extra/',\n",
    "        model=model,\n",
    "        train_ds=train_ds_nueva,\n",
    "        valid_ds=val_ds_nueva,\n",
    "        training=True,\n",
    "    )\n",
    "    # Inicia el entrenamiento\n",
    "    learner.train(epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUSCAR NUEVA DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rastervision.pytorch_learner import SemanticSegmentationLearner\n",
    "\n",
    "learner = SemanticSegmentationLearner.from_model_bundle(\n",
    "    model_bundle_uri=f'data/models/bundle_{n_epochs}/model-bundle.zip',\n",
    "    output_dir=f'data/models/bundle_{n_epochs}_extra/',\n",
    "    model=model,\n",
    "    train_ds=train_ds_nueva,\n",
    "    valid_ds=val_ds_nueva,\n",
    "    training=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicia el entrenamiento\n",
    "learner.train(epochs=n_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssmodel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
